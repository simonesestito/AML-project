{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Replicate SAPLMA\n",
        "In this notebook, we aim to replicate what the original paper has done, in order to have a working baseline.\n",
        "\n",
        "Source: https://arxiv.org/pdf/2304.13734"
      ],
      "metadata": {
        "id": "WvYDGgUYiiKI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports, installations and declarations from previous notebooks\n",
        "\n",
        "This section can be skipped and collapsed."
      ],
      "metadata": {
        "id": "uXknG8gh2l6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Drive, if needed, and check the HF_TOKEN is set and accessible\n",
        "import os\n",
        "from google.colab import drive, userdata\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "DRIVE_PATH: str = '/content/drive/MyDrive/Final_Project/'\n",
        "assert os.path.exists(DRIVE_PATH), 'Did you forget to create a shortcut in MyDrive named Final_Project this time as well? :('\n",
        "%cd {DRIVE_PATH}\n",
        "!ls\n",
        "\n",
        "print()\n",
        "assert userdata.get('HF_TOKEN'), 'Set up HuggingFace login secret properly in Colab!'\n",
        "print('HF_TOKEN found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJq0xkuVyLFx",
        "outputId": "34d0472a-7b5a-4a23-e498-9f9e373a2445",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/.shortcut-targets-by-id/1WdIP20OinXKeEN_xVOHEa6WVcY4eSO-k/Final_Project\n",
            " 1_experiments_on_llama_and_saplma.ipynb   hallucination_detector\n",
            " 2_replicate_saplma.ipynb\t\t   publicDataset\n",
            "'AML - First presentation.gslides'\t   X_create_saplma_tensors_dataset.ipynb\n",
            "\n",
            "HF_TOKEN found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 1\n",
        "%aimport hallucination_detector\n",
        "import hallucination_detector"
      ],
      "metadata": {
        "id": "r3aWt5Cx9ddW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971f74df-0800-444d-807b-e4e542adcfa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone the new updated Python files from GitHub, from master\n",
        "!mkdir -p /root/.ssh\n",
        "!touch /root/.ssh/id_ecdsa\n",
        "\n",
        "with open('/root/.ssh/id_ecdsa', 'w') as f:\n",
        "  f.write(\"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\n",
        "b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\n",
        "QyNTUxOQAAACBN5OyyeJAQryI/zwNLvd+zMEVd6XBK0Ja98k3Ig7FbqAAAAJhQG7vQUBu7\n",
        "0AAAAAtzc2gtZWQyNTUxOQAAACBN5OyyeJAQryI/zwNLvd+zMEVd6XBK0Ja98k3Ig7FbqA\n",
        "AAAEB3FBQaCkBDBXcSzkqsCiF1STPZPg5iv4eoDspA0KEHsE3k7LJ4kBCvIj/PA0u937Mw\n",
        "RV3pcErQlr3yTciDsVuoAAAAEHNpbW9uZUBhcmNobGludXgBAgMEBQ==\n",
        "-----END OPENSSH PRIVATE KEY-----\\n\"\"\")\n",
        "\n",
        "with open('/root/.ssh/known_hosts', 'w') as f:\n",
        "  f.write(\"github.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOMqqnkVzrm0SdG6UOoqKLsabgH5C9okWi0dh2l9GKJl\\n\")\n",
        "  f.write(\"github.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCj7ndNxQowgcQnjshcLrqPEiiphnt+VTTvDP6mHBL9j1aNUkY4Ue1gvwnGLVlOhGeYrnZaMgRK6+PKCUXaDbC7qtbW8gIkhL7aGCsOr/C56SJMy/BCZfxd1nWzAOxSDPgVsmerOBYfNqltV9/hWCqBywINIR+5dIg6JTJ72pcEpEjcYgXkE2YEFXV1JHnsKgbLWNlhScqb2UmyRkQyytRLtL+38TGxkxCflmO+5Z8CSSNY7GidjMIZ7Q4zMjA2n1nGrlTDkzwDCsw+wqFPGQA179cnfGWOWRVruj16z6XyvxvjJwbz0wQZ75XK5tKSb7FNyeIEs4TT4jk+S4dhPeAUC5y+bDYirYgM4GC7uEnztnZyaVWQ7B381AK4Qdrwt51ZqExKbQpTUNn+EjqoTwvqNj4kqx5QUCI0ThS/YkOxJCXmPUWZbhjpCg56i+2aB6CmK2JGhn57K5mj0MNdBXA4/WnwH6XoPWJzK5Nyu2zB3nAZp+S5hpQs+p1vN1/wsjk=\\n\")\n",
        "  f.write(\"github.com ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBEmKSENjQEezOmxkZMy7opKgwFB9nkt5YRrYMjNuG5N87uRgg6CLrbo5wAdT/y6v0mKV0U2w0WZ2YB/++Tpockg=\\n\")\n",
        "\n",
        "!chmod 400 ~/.ssh/id_ecdsa ~/.ssh/known_hosts\n",
        "!ls ~/.ssh\n",
        "\n",
        "# Clone the repository\n",
        "!rm -rf /content/AML-project {DRIVE_PATH}/hallucination_detector\n",
        "!git clone git@github.com:simonesestito/AML-project.git --depth=1 /content/AML-project\n",
        "!mv /content/AML-project/hallucination_detector {DRIVE_PATH}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhcEU8LsEQ0x",
        "outputId": "ea085272-d69a-47c2-d17d-f166c740b955"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id_ecdsa  id_rsa  known_hosts\n",
            "Cloning into '/content/AML-project'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 23 (delta 1), reused 17 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (23/23), 52.68 KiB | 13.17 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize Llama"
      ],
      "metadata": {
        "id": "VH6mBr9c63jm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IOdwRgjkQvO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from hallucination_detector.llama import LlamaInstruct\n",
        "from hallucination_detector.dataset import StatementDataset\n",
        "from hallucination_detector.extractor import LlamaHiddenStatesExtractor\n",
        "from hallucination_detector.classifier import OriginalSAPLMAClassifier\n",
        "\n",
        "torch.set_default_dtype(torch.float16)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGmDcnZQMpBe"
      },
      "outputs": [],
      "source": [
        "llama = LlamaInstruct()\n",
        "assert llama.device.type == 'cuda', 'The model should be running on a GPU. On CPU, it is impossible to run'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement SAPLMA original model"
      ],
      "metadata": {
        "id": "JhOnYO3D6-tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = StatementDataset.load_from_directory('publicDataset')\n",
        "print(f'Found {len(dataset)} samples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i1eT6hA91EG",
        "outputId": "2cd8c0f9-ecdf-4759-a002-6d0231557860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading file: cities_true_false.csv\n",
            "Loading file: animals_true_false.csv\n",
            "Loading file: elements_true_false.csv\n",
            "Loading file: inventions_true_false.csv\n",
            "Loading file: companies_true_false.csv\n",
            "Loading file: generated_true_false.csv\n",
            "Loading file: facts_true_false.csv\n",
            "Found 6330 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_saplma = OriginalSAPLMAClassifier()\n",
        "original_saplma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgrxmaaY-piE",
        "outputId": "07259d67-f716-4be8-aa35-d37f5a6577c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OriginalSAPLMAClassifier(\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
              "    (7): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_extractor = LlamaHiddenStatesExtractor(llama)\n",
        "hidden_extractor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nMydoVr--Pw",
        "outputId": "e4c980ee-cb78-4b03-fbd5-fc4b356d089b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<hallucination_detector.extractor.hidden_states.LlamaHiddenStatesExtractor at 0x7a32249abd30>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the SAPLMA classifier\n",
        "\n",
        "According to the original paper, including the hidden layer index, and so on.\n",
        "\n",
        "The only difference is that we are using llama **3.2** instead of version 2."
      ],
      "metadata": {
        "id": "LrHaGygeACBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# topics\n",
        "topics = dataset.get_topics()\n",
        "print(f'Found {len(topics)} topics')"
      ],
      "metadata": {
        "id": "pAe2lw2bAWko",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "1b09dcb4-f440-4ca7-948a-3368d8581637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'StatementDataset' object has no attribute 'get_topics'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-dbfe3f9ed617>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtopics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Found {len(topics)} topics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'StatementDataset' object has no attribute 'get_topics'"
          ]
        }
      ]
    }
  ]
}